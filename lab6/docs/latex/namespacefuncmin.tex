\doxysection{funcmin Namespace Reference}
\hypertarget{namespacefuncmin}{}\label{namespacefuncmin}\index{funcmin@{funcmin}}


Namespace containing function minimization algorithms.  


\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
int \mbox{\hyperlink{namespacefuncmin_a07939512747e3786b6a1c38ebc0ebecf}{trs\+Eig}} (const Eigen\+::\+Matrix\+Xd \&H, const Eigen\+::\+Vector\+Xd \&g, double D, Eigen\+::\+Vector\+Xd \&p)
\begin{DoxyCompactList}\small\item\em Solve trust-\/region subproblem. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{namespacefuncmin_a07454c34d31cc7a3d436630645c29314}{trs\+Eig}} (const Eigen\+::\+Matrix\+Xd \&Q, const Eigen\+::\+Vector\+Xd \&v, const Eigen\+::\+Vector\+Xd \&g, double D, Eigen\+::\+Vector\+Xd \&p)
\begin{DoxyCompactList}\small\item\em Solve trust-\/region subproblem with pre-\/computed eigendecomposition. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{namespacefuncmin_aafd08c8cf500feab0ebf4a452c0a88be}{trs\+Sqrt}} (const Eigen\+::\+Matrix\+Xd \&Xi, const Eigen\+::\+Vector\+Xd \&g, double D, Eigen\+::\+Vector\+Xd \&p)
\begin{DoxyCompactList}\small\item\em Solve trust-\/region subproblem with square-\/root Hessian. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{namespacefuncmin_a4efa83f70a0a4d1da8401dde4a558b97}{trs\+Sqrt\+Sparse}} (const Eigen\+::\+Sparse\+Matrix$<$ double $>$ \&Xi, const Eigen\+::\+Permutation\+Matrix$<$ Eigen\+::\+Dynamic $>$ \&Pi, const Eigen\+::\+Vector\+Xd \&g, double D, Eigen\+::\+Vector\+Xd \&p)
\begin{DoxyCompactList}\small\item\em Solve trust-\/region subproblem with sparse square-\/root Hessian. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{namespacefuncmin_ac35752d9f2d6d61e5df0ba0542d5910d}{trs\+Sqrt\+Inv}} (const Eigen\+::\+Matrix\+Xd \&S, const Eigen\+::\+Vector\+Xd \&g, double D, Eigen\+::\+Vector\+Xd \&p)
\begin{DoxyCompactList}\small\item\em Solve trust-\/region subproblem with square-\/root inverse Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a177ce87c99954482d2836fb7ec0ec8d1}{Newton\+Trust\+Eig}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&Q, Eigen\+::\+Vector\+Xd \&v, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region Newton method with eigendecomposition. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a7610fb352ec73e4da5add06ab144d139}{Newton\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region Newton method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a345194296ea671b071e1ec040efef32e}{Newton\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region Newton method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a6ab4305064c9339f40232d606e5693a6}{Newton\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region Newton method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename T$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a90123447966b46b5a0861a34b68f16dc}{sgn}} (T val)
\begin{DoxyCompactList}\small\item\em Sign function. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a5bce3224539c2de39f587273194b07f9}{SR1\+Trust\+Eig}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&Q, Eigen\+::\+Vector\+Xd \&v, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a6b7cf99bbc1aef61696e16452998f81c}{SR1\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a06c21cb0ac4a81c59005ea2ac4eb618b}{SR1\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_adffedbd691dce92b26edfb6d56c8c96f}{SR1\+Trust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_ac1f73e1e0cf8ec583ff407b4db1bc470}{BFGSTrust\+Sqrt}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&Xi, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with square-\/root Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a50c78b531d01ee12ab57fac2fa026c64}{BFGSTrust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a7b84b4d95417401f7872c1c2d44d06fd}{BFGSTrust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a0f028cd54a9e280ba9f798d463a2489d}{BFGSTrust}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a002b08f44db1089b601526b027f35e45}{BFGSTrust\+Sqrt\+Sparse}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Sparse\+Matrix$<$ double $>$ \&Xi, Eigen\+::\+Permutation\+Matrix$<$ Eigen\+::\+Dynamic $>$ \&Pi, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse square-\/root Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a29960a3385a5a312048d348491ca5830}{BFGSTrust\+Sparse}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a4d2d5d03bbf4f6461c3580a0dc436d92}{BFGSTrust\+Sparse}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a0d2dae1ed415dec481e46614765045f4}{BFGSTrust\+Sparse}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a1f4d972989b5a583f5fdc8e70d87ebaa}{BFGSTrust\+Sqrt\+Inv}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&S, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with square-\/root inverse Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a4bba38561b6514f722b6878fdf9381a0}{BFGSTrust\+Inv}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method with inverse Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_ac27869fdf9c701651280265739faba63}{BFGSTrust\+Inv}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method with inverse Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_af20e21a733457f03ccffe0cbfb14f0ba}{BFGSTrust\+Inv}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS trust-\/region method with inverse Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_aa0ef432f7bf2f373a36fe1a0a5ed986f}{BFGSLMSqrt}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&Xi, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using Levenberg-\/\+Marquardt quasi-\/\+Newton BFGS method with square-\/root Hessian. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a867b4540fa51827a73fe33a6e9ff09de}{BFGSLM}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, Eigen\+::\+Matrix\+Xd \&H, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_a00ba900dd12b931cca42c9440c400e19}{BFGSLM}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, Eigen\+::\+Vector\+Xd \&g, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Func$>$ }\\int \mbox{\hyperlink{namespacefuncmin_aa7255f9a4333476845bc6527fd280ecb}{BFGSLM}} (Func cost\+Func, Eigen\+::\+Vector\+Xd \&x, int verbosity=0)
\begin{DoxyCompactList}\small\item\em Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Namespace containing function minimization algorithms. 

\label{doc-func-members}
\Hypertarget{namespacefuncmin_doc-func-members}
\doxysubsection{Function Documentation}
\Hypertarget{namespacefuncmin_a867b4540fa51827a73fe33a6e9ff09de}\index{funcmin@{funcmin}!BFGSLM@{BFGSLM}}
\index{BFGSLM@{BFGSLM}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSLM()}{BFGSLM()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a867b4540fa51827a73fe33a6e9ff09de} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSLM (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. 

This function minimizes the cost function f(x) using a BFGS Levenberg-\/\+Marquardt method. It computes and returns the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a00ba900dd12b931cca42c9440c400e19}\index{funcmin@{funcmin}!BFGSLM@{BFGSLM}}
\index{BFGSLM@{BFGSLM}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSLM()}{BFGSLM()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a00ba900dd12b931cca42c9440c400e19} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSLM (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. 

This function minimizes the cost function f(x) using a BFGS Levenberg-\/\+Marquardt method. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_aa7255f9a4333476845bc6527fd280ecb}\index{funcmin@{funcmin}!BFGSLM@{BFGSLM}}
\index{BFGSLM@{BFGSLM}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSLM()}{BFGSLM()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_aa7255f9a4333476845bc6527fd280ecb} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSLM (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS Levenberg-\/\+Marquardt method. 

This function minimizes the cost function f(x) using a BFGS Levenberg-\/\+Marquardt method. It does not return the gradient or Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_aa0ef432f7bf2f373a36fe1a0a5ed986f}\index{funcmin@{funcmin}!BFGSLMSqrt@{BFGSLMSqrt}}
\index{BFGSLMSqrt@{BFGSLMSqrt}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSLMSqrt()}{BFGSLMSqrt()}}
{\footnotesize\ttfamily \label{namespacefuncmin_aa0ef432f7bf2f373a36fe1a0a5ed986f} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSLMSqrt (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{Xi}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using Levenberg-\/\+Marquardt quasi-\/\+Newton BFGS method with square-\/root Hessian. 

This function minimizes the cost function f(x) using a Levenberg-\/\+Marquardt quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method. It uses a square-\/root representation of the Hessian matrix for improved numerical stability.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{in,out}}  & {\em Xi} & Square-\/root of the Hessian matrix (upper triangular) \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a50c78b531d01ee12ab57fac2fa026c64}\index{funcmin@{funcmin}!BFGSTrust@{BFGSTrust}}
\index{BFGSTrust@{BFGSTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrust()}{BFGSTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a50c78b531d01ee12ab57fac2fa026c64} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method. It computes and returns the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a7b84b4d95417401f7872c1c2d44d06fd}\index{funcmin@{funcmin}!BFGSTrust@{BFGSTrust}}
\index{BFGSTrust@{BFGSTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrust()}{BFGSTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a7b84b4d95417401f7872c1c2d44d06fd} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a0f028cd54a9e280ba9f798d463a2489d}\index{funcmin@{funcmin}!BFGSTrust@{BFGSTrust}}
\index{BFGSTrust@{BFGSTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrust()}{BFGSTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a0f028cd54a9e280ba9f798d463a2489d} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method. It does not return the gradient or Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a4bba38561b6514f722b6878fdf9381a0}\index{funcmin@{funcmin}!BFGSTrustInv@{BFGSTrustInv}}
\index{BFGSTrustInv@{BFGSTrustInv}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustInv()}{BFGSTrustInv()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a4bba38561b6514f722b6878fdf9381a0} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Inv (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method with inverse Hessian. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method with inverse Hessian approximation. It computes and returns the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_ac27869fdf9c701651280265739faba63}\index{funcmin@{funcmin}!BFGSTrustInv@{BFGSTrustInv}}
\index{BFGSTrustInv@{BFGSTrustInv}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustInv()}{BFGSTrustInv()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_ac27869fdf9c701651280265739faba63} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Inv (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method with inverse Hessian. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method with inverse Hessian approximation. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_af20e21a733457f03ccffe0cbfb14f0ba}\index{funcmin@{funcmin}!BFGSTrustInv@{BFGSTrustInv}}
\index{BFGSTrustInv@{BFGSTrustInv}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustInv()}{BFGSTrustInv()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_af20e21a733457f03ccffe0cbfb14f0ba} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Inv (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using BFGS trust-\/region method with inverse Hessian. 

This function minimizes the cost function f(x) using a BFGS trust-\/region method with inverse Hessian approximation. It does not return the gradient or Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a29960a3385a5a312048d348491ca5830}\index{funcmin@{funcmin}!BFGSTrustSparse@{BFGSTrustSparse}}
\index{BFGSTrustSparse@{BFGSTrustSparse}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSparse()}{BFGSTrustSparse()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a29960a3385a5a312048d348491ca5830} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sparse (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method with sparse matrix representation for improved memory efficiency in large-\/scale optimization problems. It computes and returns the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This variant uses sparse matrix operations internally but returns a dense Hessian matrix. It is suitable for problems where the Hessian structure can benefit from sparse storage during optimization but a dense result is desired. 
\end{DoxyNote}
\Hypertarget{namespacefuncmin_a4d2d5d03bbf4f6461c3580a0dc436d92}\index{funcmin@{funcmin}!BFGSTrustSparse@{BFGSTrustSparse}}
\index{BFGSTrustSparse@{BFGSTrustSparse}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSparse()}{BFGSTrustSparse()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a4d2d5d03bbf4f6461c3580a0dc436d92} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sparse (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method with sparse matrix representation for improved memory efficiency in large-\/scale optimization problems. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This variant is optimized for large-\/scale problems where memory usage is a concern and the final Hessian matrix is not needed. 
\end{DoxyNote}
\Hypertarget{namespacefuncmin_a0d2dae1ed415dec481e46614765045f4}\index{funcmin@{funcmin}!BFGSTrustSparse@{BFGSTrustSparse}}
\index{BFGSTrustSparse@{BFGSTrustSparse}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSparse()}{BFGSTrustSparse()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a0d2dae1ed415dec481e46614765045f4} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sparse (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse matrices. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method with sparse matrix representation for improved memory efficiency in large-\/scale optimization problems. It does not return the gradient or Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This is the most memory-\/efficient variant, suitable for large-\/scale optimization problems where only the optimal solution is needed. 
\end{DoxyNote}
\Hypertarget{namespacefuncmin_ac1f73e1e0cf8ec583ff407b4db1bc470}\index{funcmin@{funcmin}!BFGSTrustSqrt@{BFGSTrustSqrt}}
\index{BFGSTrustSqrt@{BFGSTrustSqrt}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSqrt()}{BFGSTrustSqrt()}}
{\footnotesize\ttfamily \label{namespacefuncmin_ac1f73e1e0cf8ec583ff407b4db1bc470} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sqrt (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{Xi}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with square-\/root Hessian. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method. It uses a square-\/root representation of the Hessian matrix for improved numerical stability.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{in,out}}  & {\em Xi} & Square-\/root of the Hessian matrix (upper triangular) \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a1f4d972989b5a583f5fdc8e70d87ebaa}\index{funcmin@{funcmin}!BFGSTrustSqrtInv@{BFGSTrustSqrtInv}}
\index{BFGSTrustSqrtInv@{BFGSTrustSqrtInv}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSqrtInv()}{BFGSTrustSqrtInv()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a1f4d972989b5a583f5fdc8e70d87ebaa} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sqrt\+Inv (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{S}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with square-\/root inverse Hessian. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method. It uses a square-\/root representation of the inverse Hessian matrix for improved numerical stability.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{in,out}}  & {\em S} & Square-\/root of the inverse Hessian matrix (upper triangular) \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a002b08f44db1089b601526b027f35e45}\index{funcmin@{funcmin}!BFGSTrustSqrtSparse@{BFGSTrustSqrtSparse}}
\index{BFGSTrustSqrtSparse@{BFGSTrustSqrtSparse}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{BFGSTrustSqrtSparse()}{BFGSTrustSqrtSparse()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a002b08f44db1089b601526b027f35e45} 
template$<$typename Func$>$ \\
int funcmin\+::\+BFGSTrust\+Sqrt\+Sparse (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Sparse\+Matrix$<$ double $>$ \&}]{Xi}{, }\item[{Eigen\+::\+Permutation\+Matrix$<$ Eigen\+::\+Dynamic $>$ \&}]{Pi}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton BFGS method with sparse square-\/root Hessian. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton BFGS (Broyden-\/\+Fletcher-\/\+Goldfarb-\/\+Shanno) method. It uses a sparse square-\/root representation of the Hessian matrix for improved numerical stability and memory efficiency when dealing with large sparse problems. The Hessian approximation is maintained as H = Pi\texorpdfstring{$\ast$}{*}\+Xi\texorpdfstring{$^\wedge$}{\string^}\+T\texorpdfstring{$\ast$}{*}\+Xi\texorpdfstring{$\ast$}{*}\+Pi\texorpdfstring{$^\wedge$}{\string^}T where Xi is sparse upper triangular and Pi is a permutation matrix for fill-\/in reduction.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{in,out}}  & {\em Xi} & Sparse square-\/root of the Hessian matrix (upper triangular) \\
\hline
\mbox{\texttt{in,out}}  & {\em Pi} & Permutation matrix for column pivoting to reduce fill-\/in \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This variant is particularly efficient for large-\/scale optimization problems where the Hessian has a sparse structure that can be exploited. 
\end{DoxyNote}
\Hypertarget{namespacefuncmin_a7610fb352ec73e4da5add06ab144d139}\index{funcmin@{funcmin}!NewtonTrust@{NewtonTrust}}
\index{NewtonTrust@{NewtonTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{NewtonTrust()}{NewtonTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a7610fb352ec73e4da5add06ab144d139} 
template$<$typename Func$>$ \\
int funcmin\+::\+Newton\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region Newton method. 

This function minimizes the cost function f(x) using a trust-\/region Newton method. It computes the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient and Hessian \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a345194296ea671b071e1ec040efef32e}\index{funcmin@{funcmin}!NewtonTrust@{NewtonTrust}}
\index{NewtonTrust@{NewtonTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{NewtonTrust()}{NewtonTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a345194296ea671b071e1ec040efef32e} 
template$<$typename Func$>$ \\
int funcmin\+::\+Newton\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region Newton method. 

This function minimizes the cost function f(x) using a trust-\/region Newton method. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient and Hessian \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a6ab4305064c9339f40232d606e5693a6}\index{funcmin@{funcmin}!NewtonTrust@{NewtonTrust}}
\index{NewtonTrust@{NewtonTrust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{NewtonTrust()}{NewtonTrust()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a6ab4305064c9339f40232d606e5693a6} 
template$<$typename Func$>$ \\
int funcmin\+::\+Newton\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region Newton method. 


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient and Hessian \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a177ce87c99954482d2836fb7ec0ec8d1}\index{funcmin@{funcmin}!NewtonTrustEig@{NewtonTrustEig}}
\index{NewtonTrustEig@{NewtonTrustEig}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{NewtonTrustEig()}{NewtonTrustEig()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a177ce87c99954482d2836fb7ec0ec8d1} 
template$<$typename Func$>$ \\
int funcmin\+::\+Newton\+Trust\+Eig (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{Q}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{v}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region Newton method with eigendecomposition. 

This function minimizes the cost function f(x) using a trust-\/region Newton method. It uses eigendecomposition of the Hessian matrix for solving the trust-\/region subproblem.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient and Hessian \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em Q} & Eigenvectors of the Hessian at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em v} & Eigenvalues of the Hessian at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a90123447966b46b5a0861a34b68f16dc}\index{funcmin@{funcmin}!sgn@{sgn}}
\index{sgn@{sgn}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{sgn()}{sgn()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a90123447966b46b5a0861a34b68f16dc} 
template$<$typename T$>$ \\
int funcmin\+::sgn (\begin{DoxyParamCaption}\item[{T}]{val}{}\end{DoxyParamCaption})}



Sign function. 

Returns the sign of a value.


\begin{DoxyTemplParams}{Template Parameters}
{\em T} & The type of the input value \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em val} & The input value \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
int 
\end{DoxyReturn}

\begin{DoxyRetVals}{Return values}
{\em -\/1} & if val \texorpdfstring{$<$}{<} 0 \\
\hline
{\em 0} & if val = 0 \\
\hline
{\em 1} & if val \texorpdfstring{$>$}{>} 0 \\
\hline
\end{DoxyRetVals}
\Hypertarget{namespacefuncmin_a6b7cf99bbc1aef61696e16452998f81c}\index{funcmin@{funcmin}!SR1Trust@{SR1Trust}}
\index{SR1Trust@{SR1Trust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{SR1Trust()}{SR1Trust()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a6b7cf99bbc1aef61696e16452998f81c} 
template$<$typename Func$>$ \\
int funcmin\+::\+SR1\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton SR1 method. It computes and returns the Hessian matrix as part of the optimization process.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em H} & Hessian matrix at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a06c21cb0ac4a81c59005ea2ac4eb618b}\index{funcmin@{funcmin}!SR1Trust@{SR1Trust}}
\index{SR1Trust@{SR1Trust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{SR1Trust()}{SR1Trust()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a06c21cb0ac4a81c59005ea2ac4eb618b} 
template$<$typename Func$>$ \\
int funcmin\+::\+SR1\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton SR1 method. It does not return the Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_adffedbd691dce92b26edfb6d56c8c96f}\index{funcmin@{funcmin}!SR1Trust@{SR1Trust}}
\index{SR1Trust@{SR1Trust}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{SR1Trust()}{SR1Trust()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{namespacefuncmin_adffedbd691dce92b26edfb6d56c8c96f} 
template$<$typename Func$>$ \\
int funcmin\+::\+SR1\+Trust (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton SR1 method. It does not return the gradient or Hessian matrix.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a5bce3224539c2de39f587273194b07f9}\index{funcmin@{funcmin}!SR1TrustEig@{SR1TrustEig}}
\index{SR1TrustEig@{SR1TrustEig}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{SR1TrustEig()}{SR1TrustEig()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a5bce3224539c2de39f587273194b07f9} 
template$<$typename Func$>$ \\
int funcmin\+::\+SR1\+Trust\+Eig (\begin{DoxyParamCaption}\item[{Func}]{cost\+Func}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{x}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{Eigen\+::\+Matrix\+Xd \&}]{Q}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{v}{, }\item[{int}]{verbosity}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Minimize f(x) using trust-\/region quasi-\/\+Newton SR1 method. 

This function minimizes the cost function f(x) using a trust-\/region quasi-\/\+Newton SR1 (Symmetric Rank-\/1) method. It updates the Hessian approximation using the SR1 update formula.


\begin{DoxyTemplParams}{Template Parameters}
{\em Func} & Type of the cost function \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}[1]{Parameters}
 & {\em cost\+Func} & Cost function that returns f(x) and computes gradient \\
\hline
\mbox{\texttt{in,out}}  & {\em x} & Initial guess on input, optimal solution on output \\
\hline
\mbox{\texttt{out}}  & {\em g} & Gradient vector at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em Q} & Eigenvectors of the Hessian at the optimal solution \\
\hline
\mbox{\texttt{out}}  & {\em v} & Eigenvalues of the Hessian at the optimal solution \\
\hline
 & {\em verbosity} & Verbosity level (0\+: silent, 1\+: dots, 2\+: summary, 3\+: iteration details) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
int 0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a07939512747e3786b6a1c38ebc0ebecf}\index{funcmin@{funcmin}!trsEig@{trsEig}}
\index{trsEig@{trsEig}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{trsEig()}{trsEig()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a07939512747e3786b6a1c38ebc0ebecf} 
int funcmin\+::trs\+Eig (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{H}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{double}]{D}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{p}{}\end{DoxyParamCaption})}



Solve trust-\/region subproblem. 

This function solves the following trust-\/region subproblem\+:      \[\begin{aligned}
\text{minimize} \quad & \frac12 \mathbf{p}^\mathsf{T} \mathbf{H} \mathbf{p} + \mathbf{g}^\mathsf{T} \mathbf{p} \\
\text{subject to} \quad & \Vert \mathbf{p} \Vert \leq D
\end{aligned}
\]


\begin{DoxyParams}[1]{Parameters}
 & {\em H} & Hessian matrix \\
\hline
 & {\em g} & Gradient vector \\
\hline
 & {\em D} & Trust region radius \\
\hline
\mbox{\texttt{out}}  & {\em p} & Solution vector \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxySeeAlso}{See also}
Moré, J.\+J. and D.\+C. Sorensen, "{}\+Computing a Trust Region Step"{}, SIAM Journal on Scientific and Statistical Computing, Vol. 3, pp. 553-\/572, 1983. 
\end{DoxySeeAlso}
\Hypertarget{namespacefuncmin_a07454c34d31cc7a3d436630645c29314}\index{funcmin@{funcmin}!trsEig@{trsEig}}
\index{trsEig@{trsEig}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{trsEig()}{trsEig()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{namespacefuncmin_a07454c34d31cc7a3d436630645c29314} 
int funcmin\+::trs\+Eig (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{Q}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{v}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{double}]{D}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{p}{}\end{DoxyParamCaption})}



Solve trust-\/region subproblem with pre-\/computed eigendecomposition. 

This function solves the following trust-\/region subproblem given the eigendecomposition H = Q\texorpdfstring{$\ast$}{*}diag(v)\texorpdfstring{$\ast$}{*}Q\textquotesingle{}\+:      \[\begin{aligned}
\text{minimize} \quad & \frac12 \mathbf{p}^\mathsf{T} \mathbf{H} \mathbf{p} + \mathbf{g}^\mathsf{T} \mathbf{p} \\
\text{subject to} \quad & \Vert \mathbf{p} \Vert \leq D
\end{aligned}
\]


\begin{DoxyParams}[1]{Parameters}
 & {\em Q} & Eigenvectors of H \\
\hline
 & {\em v} & Eigenvalues of H \\
\hline
 & {\em g} & Gradient vector \\
\hline
 & {\em D} & Trust region radius \\
\hline
\mbox{\texttt{out}}  & {\em p} & Solution vector \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_aafd08c8cf500feab0ebf4a452c0a88be}\index{funcmin@{funcmin}!trsSqrt@{trsSqrt}}
\index{trsSqrt@{trsSqrt}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{trsSqrt()}{trsSqrt()}}
{\footnotesize\ttfamily \label{namespacefuncmin_aafd08c8cf500feab0ebf4a452c0a88be} 
int funcmin\+::trs\+Sqrt (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{Xi}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{double}]{D}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{p}{}\end{DoxyParamCaption})}



Solve trust-\/region subproblem with square-\/root Hessian. 

This function solves the following trust-\/region subproblem\+:      \[\begin{aligned}
\text{minimize} \quad & \frac12 \mathbf{p}^\mathsf{T} \boldsymbol\Xi^\mathsf{T}\boldsymbol\Xi \mathbf{p} + \mathbf{g}^\mathsf{T} \mathbf{p} \\
\text{subject to} \quad & \Vert \boldsymbol\Xi\mathbf{p} \Vert \leq D
\end{aligned}
\]


\begin{DoxyParams}[1]{Parameters}
 & {\em Xi} & Square-\/root Hessian matrix (upper triangular) \\
\hline
 & {\em g} & Gradient vector \\
\hline
 & {\em D} & Trust region radius \\
\hline
\mbox{\texttt{out}}  & {\em p} & Solution vector \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_ac35752d9f2d6d61e5df0ba0542d5910d}\index{funcmin@{funcmin}!trsSqrtInv@{trsSqrtInv}}
\index{trsSqrtInv@{trsSqrtInv}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{trsSqrtInv()}{trsSqrtInv()}}
{\footnotesize\ttfamily \label{namespacefuncmin_ac35752d9f2d6d61e5df0ba0542d5910d} 
int funcmin\+::trs\+Sqrt\+Inv (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{S}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{double}]{D}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{p}{}\end{DoxyParamCaption})}



Solve trust-\/region subproblem with square-\/root inverse Hessian. 

This function solves the following trust-\/region subproblem\+:      \[\begin{aligned}
\text{minimize} \quad & \frac12 \mathbf{p}^\mathsf{T} (\mathbf{S}^\mathsf{T}\mathbf{S})^{-1} \mathbf{p} + \mathbf{g}^\mathsf{T} \mathbf{p} \\
\text{subject to} \quad & \Vert \mathbf{S}^\mathsf{-T} \mathbf{p} \Vert \leq D
\end{aligned}
\]


\begin{DoxyParams}[1]{Parameters}
 & {\em S} & Square-\/root inverse Hessian matrix (upper triangular) \\
\hline
 & {\em g} & Gradient vector \\
\hline
 & {\em D} & Trust region radius \\
\hline
\mbox{\texttt{out}}  & {\em p} & Solution vector \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure 
\end{DoxyReturn}
\Hypertarget{namespacefuncmin_a4efa83f70a0a4d1da8401dde4a558b97}\index{funcmin@{funcmin}!trsSqrtSparse@{trsSqrtSparse}}
\index{trsSqrtSparse@{trsSqrtSparse}!funcmin@{funcmin}}
\doxysubsubsection{\texorpdfstring{trsSqrtSparse()}{trsSqrtSparse()}}
{\footnotesize\ttfamily \label{namespacefuncmin_a4efa83f70a0a4d1da8401dde4a558b97} 
int funcmin\+::trs\+Sqrt\+Sparse (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Sparse\+Matrix$<$ double $>$ \&}]{Xi}{, }\item[{const Eigen\+::\+Permutation\+Matrix$<$ Eigen\+::\+Dynamic $>$ \&}]{Pi}{, }\item[{const Eigen\+::\+Vector\+Xd \&}]{g}{, }\item[{double}]{D}{, }\item[{Eigen\+::\+Vector\+Xd \&}]{p}{}\end{DoxyParamCaption})}



Solve trust-\/region subproblem with sparse square-\/root Hessian. 

This function solves the following trust-\/region subproblem with sparse matrix representation\+:      \[\begin{aligned}
\text{minimize} \quad & \frac12 \mathbf{p}^\mathsf{T} \boldsymbol\Pi \boldsymbol\Xi^\mathsf{T}\boldsymbol\Xi \boldsymbol\Pi^\mathsf{T} \mathbf{p} + \mathbf{g}^\mathsf{T} \mathbf{p} \\
\text{subject to} \quad & \Vert \boldsymbol\Xi \boldsymbol\Pi^\mathsf{T} \mathbf{p} \Vert \leq D
\end{aligned}
\]

where the Hessian approximation is H = Pi\texorpdfstring{$\ast$}{*}\+Xi\texorpdfstring{$^\wedge$}{\string^}\+T\texorpdfstring{$\ast$}{*}\+Xi\texorpdfstring{$\ast$}{*}\+Pi\texorpdfstring{$^\wedge$}{\string^}T with Xi being a sparse upper triangular matrix and Pi being a permutation matrix used for fill-\/in reduction during sparse factorization.


\begin{DoxyParams}[1]{Parameters}
 & {\em Xi} & Sparse square-\/root Hessian matrix (upper triangular) \\
\hline
 & {\em Pi} & Permutation matrix for column pivoting to reduce fill-\/in \\
\hline
 & {\em g} & Gradient vector \\
\hline
 & {\em D} & Trust region radius \\
\hline
\mbox{\texttt{out}}  & {\em p} & Solution vector \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
0 on success, non-\/zero on failure
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This variant is particularly efficient for large-\/scale optimization problems where the Hessian has a sparse structure that can be exploited to reduce memory usage and computational complexity. 
\end{DoxyNote}
